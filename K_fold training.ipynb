{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import scale, StandardScaler,FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc,confusion_matrix,roc_auc_score, precision_recall_curve\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_spectre = df.columns[4:-1]\n",
    "other_col = [\"patient_name\",'cell_name','cell_type','patient_state','spectre']\n",
    "\n",
    "# Preprocess the data\n",
    "df['cell_type'] = df['cell_type'].replace('B',1)\n",
    "df['cell_type'] = df['cell_type'].replace('TNK',0)\n",
    "\n",
    "# One hot the specter number feature\n",
    "for i in df['spectre'].unique():\n",
    "    df['spectre_'+str(int(i))] = np.where(df['spectre'] == i, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dimensionality_reduction(x_train, x_test):\n",
    "    pls = PLSRegression(n_components=20)\n",
    "\n",
    "    spectre_transformed_train = pd.DataFrame(pls.fit_transform(x_train[col_spectre], y_train)[0])\n",
    "    spectre_transformed_test = pd.DataFrame(pls.transform(x_test[col_spectre]))\n",
    "\n",
    "    col_spectre_pls = spectre_transformed_train.columns\n",
    "\n",
    "    x_train = pd.concat([x_train.iloc[:,-3:].reset_index(), spectre_transformed_train], axis=1).drop(\"index\", axis=1)\n",
    "    x_test = pd.concat([x_test.iloc[:,-3:].reset_index(), spectre_transformed_test], axis=1).drop(\"index\", axis=1)\n",
    "    \n",
    "    return x_train, x_test\n",
    "\n",
    "def scale_feature(x_train, x_test):\n",
    "    # We scale continous feature\n",
    "    \n",
    "    col_spectre_pls = x_train.columns[3:]\n",
    "    columnTransformer = ColumnTransformer([['scaler',\n",
    "                                            StandardScaler(),\n",
    "                                            col_spectre_pls]],\n",
    "                                          remainder='passthrough',\n",
    "                                          )\n",
    "\n",
    "    x_train_transformed = np.array(columnTransformer.fit_transform(x_train))\n",
    "    x_test_transformed = np.array(columnTransformer.transform(x_test))\n",
    "    return x_train_transformed, x_test_transformed\n",
    "\n",
    "def compute_metrics(test_df, verbose=False):\n",
    "    cell_test = test_df.groupby(['patient_name','cell_name']).agg({'cell_type':\"first\",\n",
    "                                                              'patient_state':\"first\",\n",
    "                                                              \"spectre\":'count',\n",
    "                                                              'prediction':\"mean\"})\n",
    "    # We one hot encode the label\n",
    "    cell_test['TNK'] = np.where(cell_test['cell_type']==0, 1, 0)\n",
    "    cell_test['B'] = np.where(cell_test['cell_type']==1, 1, 0)\n",
    "\n",
    "    # Using a threshold of 0.5, we assign label to the mean prediction of all specters for one cell\n",
    "\n",
    "    cell_test['predicted_type'] = np.where(cell_test['prediction'] < 0.4, 0, 1)\n",
    "\n",
    "    # We one hot encode the predicted label\n",
    "    cell_test['TNK_predicted'] = np.where(cell_test['predicted_type'] == 0, 1, 0)\n",
    "    cell_test['B_predicted'] = np.where(cell_test['predicted_type'] == 1, 1, 0)\n",
    "\n",
    "    # We aggregate our test set at the patient level to get the prection for each patient\n",
    "\n",
    "    patient_df = cell_test.groupby('patient_name').agg({'TNK':sum, \n",
    "                                                      'B':sum,\n",
    "                                                      'TNK_predicted':sum,\n",
    "                                                      'B_predicted':sum,\n",
    "                                                      'patient_state':\"first\", \n",
    "                                                      'spectre':'sum'})\n",
    "\n",
    "    patient_df['cell_number'] = patient_df['TNK'] + patient_df['B']\n",
    "    patient_df['ratio_B'] = patient_df['B']/patient_df['cell_number']\n",
    "    patient_df['ratio_B_predicted'] = patient_df['B_predicted']/patient_df['cell_number']\n",
    "\n",
    "    patient_df['diff_ratio'] = abs(patient_df['ratio_B_predicted'] - patient_df['ratio_B'])\n",
    "    patient_df['predicted_state'] = np.where(patient_df['ratio_B_predicted'] < 0.4, \"sain\", 'malade')\n",
    "    patient_df.sort_values(\"ratio_B\", ascending=False)\n",
    "    \n",
    "    # Error rate for healthy and sick patient\n",
    "    errors = [list(patient_df['diff_ratio'][patient_df['patient_state'] == 'malade']), \n",
    "              list(patient_df['diff_ratio'][patient_df['patient_state'] == 'sain'])]\n",
    "    \n",
    "    accuracy = len(patient_df[patient_df['predicted_state'] == patient_df['patient_state']]) / len(patient_df)\n",
    "    \n",
    "    if verbose==True:\n",
    "\n",
    "        print('Moyenne de l\\'erreur', patient_df['diff_ratio'].mean())\n",
    "        print('Variance de l\\'erreur',patient_df['diff_ratio'].var())\n",
    "        print('Patients malades bien prédit', len(patient_df[(patient_df.predicted_state == patient_df.patient_state) \\\n",
    "                                                             & (patient_df.patient_state == \"malade\")]),'/',\n",
    "                                              len(patient_df[patient_df.patient_state == 'malade']))\n",
    "\n",
    "        print('Patients sains bien prédit', len(patient_df[(patient_df.predicted_state == patient_df.patient_state) \\\n",
    "                                                             & (patient_df.patient_state == \"sain\")]),'/',\n",
    "                                              len(patient_df[patient_df.patient_state == 'sain']))\n",
    "                                          \n",
    "    return errors, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training partition 0...\n",
      "Training partition 1...\n",
      "Training partition 2...\n",
      "Training partition 3...\n",
      "Training partition 4...\n",
      "Training partition 5...\n",
      "Training partition 6...\n",
      "Training partition 7...\n",
      "Training partition 8...\n",
      "Training partition 9...\n",
      "Training partition 10...\n",
      "Training partition 11...\n",
      "Training partition 12...\n"
     ]
    }
   ],
   "source": [
    "patient_malade = list(df[df['patient_state'] == 'malade'].patient_name.unique())\n",
    "patient_sain = list(df[df['patient_state'] == 'sain'].patient_name.unique())\n",
    "\n",
    "n_partitions = []\n",
    "\n",
    "n_models = []\n",
    "\n",
    "N_PARTITIONS = 20\n",
    "N_PATIENTS_TEST = 2\n",
    "\n",
    "for i in range(N_PARTITIONS):\n",
    "    patient_test = random.sample(patient_malade, N_PATIENTS_TEST) + random.sample(patient_sain, N_PATIENTS_TEST)\n",
    "    n_partitions.append(patient_test)\n",
    "    n_models.append(RandomForestClassifier(max_depth=15,n_estimators=50))\n",
    "\n",
    "mean_errors_sick = []\n",
    "mean_errors_healthy = []\n",
    "accuracy = []\n",
    "\n",
    "# Main loop\n",
    "for i, partitions in enumerate(n_partitions):\n",
    "    \n",
    "    print('Training partition {}...'.format(i))\n",
    "    \n",
    "    x_train = df.loc[~df.patient_name.isin(partitions)]\n",
    "    y_train = df.loc[~df.patient_name.isin(partitions)]['cell_type']\n",
    "    x_test = df.loc[df.patient_name.isin(partitions)]\n",
    "    y_test = df.loc[df.patient_name.isin(partitions)]['cell_type']\n",
    "    x_train = x_train.drop(['cell_type','cell_name','patient_name','patient_state','spectre'], axis=1)\n",
    "    x_test = x_test.drop(['cell_type','cell_name','patient_name','patient_state','spectre'], axis=1)\n",
    "    \n",
    "    # Apply a Partial least squares regression to reduce the dimensionality\n",
    "    x_train, x_test = apply_dimensionality_reduction(x_train, x_test)\n",
    "    x_train, x_test = scale_feature(x_train, x_test)\n",
    "    \n",
    "    # We retrain our model on the whole train set using the best hyperparameters\n",
    "    n_models[i].fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    # Show confusion matrix\n",
    "    y_result = n_models[i].predict_proba(x_test)[:,1]\n",
    "    y_result = np.where(y_result < 0.4, 0, 1)\n",
    "    \n",
    "    # We select all the patients that was not used for training or validation\n",
    "    test_set = df[df.patient_name.isin(partitions)]\n",
    "    test_set = test_set.assign(prediction = clf.predict_proba(x_test)[:, 1])\n",
    "    \n",
    "    metrics = compute_metrics(test_set)\n",
    "    mean_errors_sick += metrics[0][0]\n",
    "    mean_errors_healthy += metrics[0][1]\n",
    "    accuracy.append(metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1276757586562666"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_errors_sick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18550728161968896"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_errors_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
